{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q2: classifying a new body of text\n",
    "- input sentence\n",
    "- split, take count of each word, create such a dictionary\n",
    "- two such corpuses [eg test cricket commentary, and a book phrase]\n",
    "\n",
    "- using a new input check similarity to previous both\n",
    "- check if new is similar to first or second one\n",
    "naive bayes somehow involved\n",
    "'''\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def readFile(filePath):\n",
    "    '''\n",
    "    opens file in filePath and returns text inside it\n",
    "    '''\n",
    "    with open(filePath, 'r') as file:\n",
    "        return file.read()\n",
    "    \n",
    "def processText(text):\n",
    "    '''\n",
    "    remove punctuation and returns in lower case\n",
    "    '''\n",
    "    lst = ['!', '.', ',', '?', ':', ';']\n",
    "    for char in lst:\n",
    "        text = text.replace(char, '')\n",
    "    return text.lower()\n",
    "\n",
    "def getWordFrequency(text):\n",
    "    '''\n",
    "    returns frequency of each word in corpus\n",
    "    '''\n",
    "    words = text.split()\n",
    "    wordFrequency = {}\n",
    "    for word in words:\n",
    "        if word in wordFrequency.keys():\n",
    "            wordFrequency[word] += 1\n",
    "        else:\n",
    "            wordFrequency[word] = 1\n",
    "    return wordFrequency\n",
    "\n",
    "\n",
    "\n",
    "# take input from user side\n",
    "corpus1_path = r'corpus1.txt'\n",
    "corpus1_text = readFile(corpus1_path)\n",
    "corpus2_path = r'corpus2.txt'\n",
    "corpus2_text = readFile(corpus2_path)\n",
    "# input_path = r''\n",
    "input_text = 'climate'\n",
    "\n",
    "# preprocessing + frequency finding\n",
    "corpus1_processed = processText(corpus1_text)\n",
    "corpus1_wordFrequency = getWordFrequency(corpus1_processed)\n",
    "\n",
    "corpus2_processed = processText(corpus2_text)\n",
    "corpus2_wordFrequency = getWordFrequency(corpus2_processed)\n",
    "\n",
    "input_processed = processText(input_text)\n",
    "input_wordFrequency = getWordFrequency(input_processed)\n",
    "\n",
    "# finding similarity using code similarity\n",
    "word_vocabulary = set(corpus1_wordFrequency.keys()).union(set(corpus2_wordFrequency.keys()))\n",
    "\n",
    "# biulding a vector based on frequency of words\n",
    "def build_vector(wordFrequency, vocabulary):\n",
    "    return np.array([wordFrequency.get(word, 0) for word in vocabulary])\n",
    "\n",
    "corpus1_vector = build_vector(corpus1_wordFrequency, word_vocabulary)\n",
    "corpus2_vector = build_vector(corpus2_wordFrequency, word_vocabulary)\n",
    "input_vector = build_vector(input_wordFrequency, word_vocabulary)\n",
    "\n",
    "# reshaping vectors\n",
    "corpus1_vector = corpus1_vector.reshape(1, -1)\n",
    "corpus2_vector = corpus2_vector.reshape(1, -1)\n",
    "input_vector = input_vector.reshape(1, -1)\n",
    "\n",
    "input_corpus1_similarity = cosine_similarity(input_vector, corpus1_vector)\n",
    "input_corpus2_similarity = cosine_similarity(input_vector, corpus2_vector)\n",
    "\n",
    "if input_corpus1_similarity > input_corpus2_similarity:\n",
    "    print(\"Similar to corpus 1\")\n",
    "else:\n",
    "    print(\"Similar to corpus 2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterator example\n",
    "\n",
    "import time\n",
    "\n",
    "class InfIterEven:\n",
    "    '''Infinite iterator to return all even numbers'''\n",
    "    def __iter__(self):\n",
    "        '''returns iterator object'''\n",
    "        self.num = 0\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        '''used to get next element'''\n",
    "        num = self.num\n",
    "        self.num += 2\n",
    "        return num\n",
    "    \n",
    "\n",
    "a = iter(InfIterEven())\n",
    "while True:\n",
    "    print(next(a))\n",
    "    time.sleep(0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create generator function that yields powers of a given number upto specified limit\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "def powerGenerator(number, power_limit):\n",
    "    init_power = 1\n",
    "    while init_power <= power_limit:\n",
    "        yield pow(number, init_power)\n",
    "        init_power += 1\n",
    "\n",
    "\n",
    "base = 2\n",
    "max_power = 10\n",
    "x = powerGenerator(base, max_power)\n",
    "# while True:\n",
    "#     print(next(x), end=\" \")\n",
    "#     time.sleep(0.50)\n",
    "for i in x:\n",
    "    print(i, end=\" \")\n",
    "    time.sleep(0.50)    \n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also use Counter from collections\n",
    "\n",
    "from collections import Counter\n",
    "words = [\"hello\", \"there\", \"hello\"]\n",
    "Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for removing punctuations\n",
    "\n",
    "textline = \"Copyright 1990, Jim Prentice, Brandon, CANADA, CANADA, Brandon.\"\n",
    "translator = str.maketrans('', '', ',-.')\n",
    "textline.translate(translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop words\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(stop_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''100west.txt\n",
    "1. read the file\n",
    "1.1 remove punctuations\n",
    "1.2 remove stopwords\n",
    "2. get a count of all words present in the file in a dictionary format\n",
    "3. convert dictionary into json format and dump into a file\n",
    "'''\n",
    "\n",
    "\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "def readFile(filePath):\n",
    "    '''opens file presint in filePath and returns text inside it'''\n",
    "    with open(filePath, 'r') as file:\n",
    "        return file.read()\n",
    "    \n",
    "\n",
    "def processText(text):\n",
    "    '''remove punctuations and stopwords and return in string format'''\n",
    "    lst = [',', '.', ';', ':', '?', '!', '\\\"', '(', ')']\n",
    "    # lst = [',.;:?!\\\"(){}[]']\n",
    "    for char in lst:\n",
    "        text = text.replace(char, ' ')\n",
    "\n",
    "    # removing stopwords\n",
    "    nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    filtered_words = [word.lower() for word in words if word.lower() not in stop_words]\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "    \n",
    "    return filtered_text\n",
    "    \n",
    "\n",
    "def getWordFrequency(text):\n",
    "    '''returns a dictionary of all word frequency'''\n",
    "    words = text.split()\n",
    "    wordFrequency = {}\n",
    "    for word in words:\n",
    "        if word in wordFrequency.keys():\n",
    "            wordFrequency[word] += 1\n",
    "        else:\n",
    "            wordFrequency[word] = 1\n",
    "    return wordFrequency\n",
    "\n",
    "\n",
    "def dumpToJsonFile(data, outputFilePath):\n",
    "    '''dump contents of dictionary data to givem filepath'''\n",
    "    with open(outputFilePath, 'w') as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# save path of file here\n",
    "filePath = r'100west.txt'\n",
    "\n",
    "# get all text within the file\n",
    "file_text = readFile(filePath)\n",
    "\n",
    "# process text to remove all punctuations\n",
    "file_processed = processText(file_text)\n",
    "\n",
    "# get dictionary of word frequencies\n",
    "file_wordFrequency = getWordFrequency(file_processed)\n",
    "\n",
    "\n",
    "\n",
    "# dump data to a json file\n",
    "dumpToJsonFile(file_wordFrequency, r'output_file.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python code implementing inheritance and encapsulation\n",
    "\n",
    "\n",
    "class Vehicle:\n",
    "    # def __init__(self):\n",
    "    #     pass\n",
    "        \n",
    "    def setName(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "    def getName(self):\n",
    "        return self.name\n",
    "    \n",
    "    def setRegistrationNumber(self, regNo):\n",
    "        self.regNo = regNo\n",
    "        \n",
    "    def getRegistrationNo(self):\n",
    "        return self.regNo\n",
    "\n",
    "    \n",
    "    \n",
    "class Car(Vehicle):\n",
    "    # def __init__(self):\n",
    "    #     self.axle = 2\n",
    "    #     self.tyres = 4\n",
    "        \n",
    "    def setPassengerCount(self, passengerCount):\n",
    "        self.passengerCount = passengerCount\n",
    "        \n",
    "    def getPassengerCount(self):\n",
    "        return self.passengerCount\n",
    "    \n",
    "    \n",
    "    \n",
    "class Truck(Vehicle):\n",
    "    # def __init__(self):\n",
    "    #     pass\n",
    "    \n",
    "    def setCargoManifest(self, cargoManifest):\n",
    "        self.cargoManifest = cargoManifest\n",
    "        \n",
    "    def getCargoManifest(self):\n",
    "        return self.cargoManifest\n",
    "    \n",
    "    def setTruckPermitId(self, permitId):\n",
    "        self.permitId = permitId\n",
    "        \n",
    "    def getPermitId(self):\n",
    "        self.permitId\n",
    "        \n",
    "        \n",
    "truckObject = Truck()\n",
    "\n",
    "truckObject.setName(\"Truck 1\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
